{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "s11_resnet_dnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/futartup/S11-assignment/blob/master/model/s11_resnet_dnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SktU4sYtpSav",
        "colab_type": "text"
      },
      "source": [
        "# **This is a model implementation of assignment s11, with resnet block**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3RfwRojpS1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j7RPQ4IqkQu",
        "colab_type": "text"
      },
      "source": [
        "Return Conv2d layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhjEcwVbqoN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d(in_channels=0, out_channels=0, filter_size=1, stride=1, padding=0, bias=False ):\n",
        "  return nn.Conv2d(in_channels, out_channels, filter_size, stride, padding, bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCd8r3GdrXhz",
        "colab_type": "text"
      },
      "source": [
        "Return Batch Normalization Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3B6nSwfrbcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batchN(in_channels=1):\n",
        "  return nn.BatchNorm2d(in_channels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4f5VZ70r3Ws",
        "colab_type": "text"
      },
      "source": [
        "Return Max Pool Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHScGJ5Mr54E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def maxpool(x=1,y=1):\n",
        "  return nn.MaxPool2d(x, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVh5w_melLhT",
        "colab_type": "text"
      },
      "source": [
        "Fully Connected Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA23f_fIlOSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fc(in_channels=1, out_channels=1):\n",
        "  return nn.Linear(in_channels, out_channels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wWsziJFWVU-",
        "colab_type": "text"
      },
      "source": [
        "Relu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCoTKrRSWWgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu():\n",
        "  return nn.ReLU()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMMfd8jCcURI",
        "colab_type": "text"
      },
      "source": [
        "Resnet Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI8SN4EDcV7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResnetBlock(nn.Module):\n",
        "  def __init__(self, topology):\n",
        "    super(ResnetBlock, self).__init__()\n",
        "    for key, val in topology.items():\n",
        "      self.r = self.make_layers(topology)\n",
        "\n",
        "  def make_layers(self, topology: dict):\n",
        "    layers = []\n",
        "    assert len(topology) > 0, \"The resnet block should contain some blocks\"\n",
        "    for key, val in topology.items():\n",
        "      for key, val in val.items():\n",
        "        layers.append(topology_mapping[key](**val))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    initial = x\n",
        "    for l in self.__dir__['_modules']:\n",
        "      out = l(x)\n",
        "      x = out\n",
        "    x += initial\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkll9ZEsP-Xl",
        "colab_type": "text"
      },
      "source": [
        "Topology Mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InAuqr6qP__n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topology_mapping = {\n",
        "    'C': conv2d,\n",
        "    'BN': batchN,\n",
        "    'MP': maxpool,\n",
        "    'FC': fc,\n",
        "    'Rel': relu,\n",
        "    'R': ResnetBlock\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JDgA5qez_GN",
        "colab_type": "text"
      },
      "source": [
        "Lets Go"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQCHzcmKz9No",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "topology = {\n",
        "    \"preparation_layer\": {\"C\":{\"in_channels\": 3,\"out_channels\": 64,\"filter_size\": 3,\"stride\": 1,\"padding\": 1, \"bias\": False,},\n",
        "                          \"BN\": { \"in_channels\": 64 },\n",
        "                          \"Rel\": {},\n",
        "                          },\n",
        "\n",
        "    \"layer1\": {\n",
        "        \"C\": {\"in_channels\": 64,\"out_channels\": 128,\"filter_size\": 3,\"stride\": 1,\"padding\": 1, \"bias\": False,},      \n",
        "        \"MP\": {  \"x\": 2, \"y\": 2 },\n",
        "        \"BN\": { \"in_channels\": 128 },\n",
        "        \"Rel\": {},\n",
        "        \"R\": {\n",
        "            \"b1\":{\n",
        "                \"C\": {\"in_channels\": 128,\"out_channels\": 128,\"filter_size\": 3,\"stride\": 1,\"padding\": 1 , \"bias\": False,},\n",
        "                \"BN\": { \"in_channels\": 128 },\n",
        "                \"Rel\": {},\n",
        "            },\n",
        "            \"b2\":{\n",
        "                \"C\": {\"in_channels\": 128,\"out_channels\": 128,\"filter_size\": 3,\"stride\": 1,\"padding\": 1 , \"bias\": False,},\n",
        "                \"BN\": { \"in_channels\": 128 },\n",
        "                \"Rel\": {},\n",
        "            },\n",
        "            \n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"layer2\": {\n",
        "        \"C\": { \"in_channels\": 128,\"out_channels\": 256,\"filter_size\": 3,\"stride\": 1,\"padding\": 1, \"bias\": False,},      \n",
        "        \"MP\": {   \"x\": 2, \"y\": 2},\n",
        "        \"BN\": {  \"in_channels\": 256 },\n",
        "        \"Rel\": {},\n",
        "    },\n",
        "\n",
        "    \"layer3\": {\n",
        "        \"C\": { \"in_channels\": 256,\"out_channels\": 512,\"filter_size\": 3,\"stride\": 1,\"padding\": 1, \"bias\": False,},      \n",
        "        \"MP\": {   \"x\": 2, \"y\": 2 },\n",
        "        \"BN\": {  \"in_channels\": 512 },\n",
        "        \"Rel\": {},\n",
        "        \"R\": {\n",
        "            \"b1\": {\n",
        "                  \"C\": { \"in_channels\": 512,\"out_channels\": 512,\"filter_size\": 3,\"stride\": 1,\"padding\": 1, \"bias\": False, },\n",
        "                  \"BN\": {   \"in_channels\": 512 },\n",
        "                  \"Rel\": {},\n",
        "            },\n",
        "            \"b2\":{\n",
        "                 \"C\": { \"in_channels\": 512,\"out_channels\": 512,\"filter_size\": 3,\"stride\": 1,\"padding\": 1 , \"bias\": False,},\n",
        "                 \"BN\": {   \"in_channels\": 512 },\n",
        "                 \"Rel\": {},\n",
        "            }\n",
        "           \n",
        "        }\n",
        "    },\n",
        "    \"maxpool_4\": {\n",
        "        \"MP\": {   \"x\": 4, \"y\": 4},\n",
        "    },\n",
        "    \"FC\": {\n",
        "        \"FC\": { \"in_channels\": 512, \"out_channels\": 10},\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "class S11(nn.Module):\n",
        "  def __init__(self, topology):\n",
        "    super(S11, self).__init__()\n",
        "    for key, val in topology.items():\n",
        "      self.__dict__['_modules'][key] = self.make_layer(val)\n",
        "\n",
        "  def make_layer(self, topology):\n",
        "    layers = []\n",
        "    for key, val in topology.items():\n",
        "      if key == 'R':\n",
        "        layers.append(ResnetBlock(val))\n",
        "      else:\n",
        "        layers.append(topology_mapping[key](**val))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.preparation_layer(x)\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.maxpool_4(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.FC(x)\n",
        "    #x = x.view(-1, 10)\n",
        "    x = F.log_softmax(x, dim=1)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE9NUryt63wy",
        "colab_type": "text"
      },
      "source": [
        "Define the Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OGbCcEU68HA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#net = S11(topology)\n",
        "\n",
        "\n",
        "# use_cuda = torch.cuda.is_available()\n",
        "# if use_cuda:\n",
        "#   torch.cuda.manual_seed(1)\n",
        "# device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "# print(device)\n",
        "# model = net.to(device)\n",
        "# summary(model, input_size=(3, 32, 32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnEy2M3cQyEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NetS11(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NetS11, self).__init__()\n",
        "\n",
        "    self.preparation_layer = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, 3, padding=1, stride=1, bias=False),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d(64, 128, 3, padding=1, stride=1, bias=False),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.layer1_resnet = nn.Sequential(\n",
        "        nn.Conv2d(128, 128, 3, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.Conv2d(128, 128, 3, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(128, 256, 3, padding=1, bias=False),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.layer3 = nn.Sequential(\n",
        "        nn.Conv2d(256, 512, 3, padding=1, stride=1, bias=False),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.layer3_resnet = nn.Sequential(\n",
        "        nn.Conv2d(512, 512, 3, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.Conv2d(512, 512, 3, padding=1, bias=False),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.maxpool_k = nn.MaxPool2d(4,4)\n",
        "\n",
        "    self.linear = nn.Linear(512, 10)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.preparation_layer(x)\n",
        "    \n",
        "    x = self.layer1(x)\n",
        "    initial = x\n",
        "    x = self.layer1_resnet(x) + initial\n",
        "    \n",
        "    x = self.layer2(x)\n",
        "\n",
        "    x = self.layer3(x)\n",
        "    initial = x\n",
        "    x = self.layer3_resnet(x) + initial\n",
        "    \n",
        "    x = self.maxpool_k(x)\n",
        "    \n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.linear(x)\n",
        "    \n",
        "    x = F.log_softmax(x, dim=1)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}